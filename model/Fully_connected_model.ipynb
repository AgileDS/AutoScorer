{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import csv, json\n",
    "import datetime\n",
    "import keras\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edf_to_dataset(edf_path, scores_path):\n",
    "    edf = mne.io.read_raw_edf(edf_path)\n",
    "    sampling_rate = int(edf.info['sfreq'])\n",
    "    name = datetime.datetime.utcfromtimestamp(edf.info['meas_date'][0]).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    header = (','.join(edf.ch_names)).split(',')\n",
    "    df = edf.get_data().T\n",
    "    \n",
    "    scores = np.squeeze( pd.read_excel(scores_path, keep_default_na=False).values )\n",
    "    values_per_window = int(df.shape[0]/scores.shape[0])\n",
    "    num_windows = scores.shape[0]\n",
    "    \n",
    "    df = df[:num_windows*values_per_window]\n",
    "    df = np.reshape(df, newshape=(num_windows, values_per_window, 2))\n",
    "\n",
    "    scores[scores=='D'] = 'WA'\n",
    "    scores[scores=='SS'] = 'WA'\n",
    "    \n",
    "    return df, scores\n",
    "\n",
    "def labels_to_onehot(Y, categories = {}):\n",
    "    Y = Y.copy()\n",
    "    count = 0\n",
    "    for i in range(len(Y)):\n",
    "        value = Y[i]\n",
    "        if not value in categories:\n",
    "            categories[value] = count\n",
    "            count += 1\n",
    "        Y[i] = categories[value]\n",
    "\n",
    "    Y = Y.astype(int)\n",
    "    Y_onehot = np.zeros((Y.shape[0], len(categories)))\n",
    "#     print(Y_onehot.shape)\n",
    "#     print(categories)\n",
    "    Y_onehot[np.arange(Y.shape[0]), Y] = 1\n",
    "\n",
    "    return Y_onehot, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh70_02202015.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh72_02142015.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh74_02032015.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh93_02272015.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh116_01292016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh118_01182016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh120_01112016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh122_01072016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh124_01052016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from C:\\Users\\Usuario\\AutoScorer\\model\\samples\\Veh128_01182016.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    }
   ],
   "source": [
    "#Import training data\n",
    "sample_folder = './samples/'\n",
    "file_name = 'Veh70_02202015'\n",
    "X_train, Y_train = edf_to_dataset(sample_folder+file_name+'.edf', sample_folder+file_name+'.xls')\n",
    "filenames = ['Veh72_02142015', 'Veh74_02032015', 'Veh93_02272015','Veh116_01292016','Veh118_01182016','Veh120_01112016', 'Veh122_01072016','Veh124_01052016']\n",
    "for file in filenames:\n",
    "    temp_X, temp_Y = edf_to_dataset(sample_folder+file+'.edf', sample_folder+file+'.xls')\n",
    "    X_train=np.append(X_train,temp_X,axis=0)\n",
    "    Y_train=np.append(Y_train,temp_Y,axis=0)\n",
    "Y_train_onehot, categories = labels_to_onehot(Y_train)\n",
    "\n",
    "#Import test data\n",
    "file_name = 'Veh128_01182016'\n",
    "X_test, Y_test = edf_to_dataset(sample_folder+file_name+'.edf', sample_folder+file_name+'.xls')\n",
    "Y_test_onehot, categories = labels_to_onehot(Y_test)\n",
    "\n",
    "#rescale and normalize data\n",
    "X_train = X_train.reshape((-1, 10000))\n",
    "X_test = X_test.reshape((-1, 10000))\n",
    "X_train_norm = preprocessing.normalize(X_train)\n",
    "X_test_norm = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "\n",
    "from keras.layers import Dropout\n",
    "model= Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(10000,)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19440/19440 [==============================] - 10s 502us/step - loss: 1.5103 - acc: 0.4331\n",
      "Epoch 2/10\n",
      "19440/19440 [==============================] - 8s 398us/step - loss: 1.3849 - acc: 0.4496\n",
      "Epoch 3/10\n",
      "19440/19440 [==============================] - 8s 388us/step - loss: 1.2533 - acc: 0.5193\n",
      "Epoch 4/10\n",
      "19440/19440 [==============================] - 8s 403us/step - loss: 1.1536 - acc: 0.5562\n",
      "Epoch 5/10\n",
      "19440/19440 [==============================] - 8s 388us/step - loss: 1.0787 - acc: 0.5781\n",
      "Epoch 6/10\n",
      "19440/19440 [==============================] - 7s 368us/step - loss: 1.0232 - acc: 0.5895\n",
      "Epoch 7/10\n",
      "19440/19440 [==============================] - 7s 360us/step - loss: 0.9938 - acc: 0.5980\n",
      "Epoch 8/10\n",
      "19440/19440 [==============================] - 7s 378us/step - loss: 0.9502 - acc: 0.6108\n",
      "Epoch 9/10\n",
      "19440/19440 [==============================] - 7s 375us/step - loss: 0.9221 - acc: 0.6202\n",
      "Epoch 10/10\n",
      "19440/19440 [==============================] - 7s 365us/step - loss: 0.8995 - acc: 0.6323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d2a0fb3828>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(\n",
    "  X_train_norm,\n",
    "  Y_train_onehot,\n",
    "  epochs=10,\n",
    "  batch_size=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 1s 313us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9740464886029562, 0.6194444444444445]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "model.evaluate(\n",
    "  X_test_norm,\n",
    "  Y_test_onehot\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('fully_connected_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
